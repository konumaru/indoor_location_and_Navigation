{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rich.progress import track\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "from utils.feature import FeatureStore\n",
    "from utils.common import load_pickle, dump_pickle, save_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pickle from ../data/scaler/scaler_wifi_rssi.pkl\n"
     ]
    }
   ],
   "source": [
    "featfure_dir = pathlib.Path(\"../data/preprocessing/\")\n",
    "\n",
    "scaler = load_pickle(f\"../data/scaler/scaler_wifi_rssi.pkl\")\n",
    "wifi_bssid = np.load(featfure_dir / \"train_wifi_bssid.npy\")\n",
    "test_wifi_bssid = np.load(\"../data/submit/test_wifi_bssid.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BSSID のラベルエンコーディングは本当に任意の処理を行えているのかを確認する\n",
    "\n",
    "- 前提\n",
    "    - Trainに存在するbssidはtestに存在するものをすべて含んでいる\n",
    "- 処理内容\n",
    "    - train の bssid をすべて取得する\n",
    "    - bssid の map を作成する\n",
    "    - 前処理の途中でlabel encodeを行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前提の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@save_cache(\"./tmp/train_unique_bssid.pkl\", True)\n",
    "def create_bssid_map(filepaths):\n",
    "    def get_bssid_from_featureStore(filepath):\n",
    "        site_id = filepath.parent.parent.name\n",
    "        floor = filepath.parent.name\n",
    "        path_id = filepath.name.split(\".\")[0]\n",
    "\n",
    "        feature = load_pickle(f\"../data/working/{path_id}.pkl\", verbose=False)\n",
    "        uniques = feature.wifi.bssid.unique()\n",
    "        if len(uniques) > 0:\n",
    "            return uniques\n",
    "        else:\n",
    "            return np.array([])\n",
    "\n",
    "    bssid = Parallel(n_jobs=-1)(\n",
    "        delayed(get_bssid_from_featureStore)(filepath) for filepath in track(filepaths)\n",
    "    )\n",
    "    bssid = np.concatenate(bssid, axis=0)\n",
    "    unique_bssid = np.unique(bssid)\n",
    "    return unique_bssid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pickle from ./tmp/train_unique_bssid.pkl\n"
     ]
    }
   ],
   "source": [
    "src_dir = pathlib.Path(\"../data/raw/train/\")\n",
    "filepaths = [\n",
    "    path_filepath\n",
    "    for site_filepath in src_dir.glob(\"*\")\n",
    "    for floor_filepath in site_filepath.glob(\"*\")\n",
    "    for path_filepath in floor_filepath.glob(\"*\")\n",
    "]\n",
    "\n",
    "train_uniques = create_bssid_map(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@save_cache(\"./tmp/test_unique_bssid.pkl\", True)\n",
    "def create_test_bssid(filepaths):\n",
    "    def get_bssid_from_featureStore(filepath):\n",
    "        site_id = filepath.parent.parent.name\n",
    "        floor = filepath.parent.name\n",
    "        path_id = filepath.name.split(\".\")[0]\n",
    "\n",
    "        feature = load_pickle(f\"../data/submit/path_data/{path_id}.pkl\", verbose=False)\n",
    "        uniques = feature.wifi.bssid.unique()\n",
    "        if len(uniques) > 0:\n",
    "            return uniques\n",
    "        else:\n",
    "            return np.array([])\n",
    "\n",
    "    bssid = Parallel(n_jobs=-1)(\n",
    "        delayed(get_bssid_from_featureStore)(filepath) for filepath in track(filepaths)\n",
    "    )\n",
    "    bssid = np.concatenate(bssid, axis=0)\n",
    "    unique_bssid = np.unique(bssid)\n",
    "    return unique_bssid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pickle from ./tmp/test_unique_bssid.pkl\n"
     ]
    }
   ],
   "source": [
    "src_dir = pathlib.Path(\"../data/submit/path_data/\")\n",
    "filepaths = [path_filepath for path_filepath in src_dir.glob(\"*\")]\n",
    "\n",
    "test_uniques = create_test_bssid(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../data/submit/path_data/504b8655852f837f2aca36a7.pkl')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepaths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00001d7b6fbf0a24da65285b686b03c6e796962a',\n",
       "       '0000fe40d201cfc6cada502b07f29883cd17fe4a',\n",
       "       '0001092dd27fe270ab0e2a652e21ea6e8320bf33', ...,\n",
       "       'ffffae79ecb8e184afbaf0f6f763ebf0bc2d49df',\n",
       "       'ffffb8116ceb5c0326ec2eb039028ec71ffdfbab',\n",
       "       'ffffcb329c1c354fb4290a8223fd99d6508ed766'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237452"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list(train_uniques)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37779"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list(test_uniques)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testにのみ存在するBSSIDの数：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1407"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('testにのみ存在するBSSIDの数：')\n",
    "len(set(list(test_uniques)) - set(list(train_uniques)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前提が間違っていた"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "167cad4144d70340325d221b52718775d7d96f3361bf0df64e0910740bdaf636"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
